Perfecto, AndrÃ©s. AquÃ­ tienes **todo tu contenido convertido a Markdown**, sin modificar nada del texto, solo dÃ¡ndole formato limpio, ordenado y perfectamente compatible con GitHub.

---

```markdown
# ğŸ“± iPhone Price Monitor

Proyecto profesional de scraping diseÃ±ado para demostrar:

- Arquitectura limpia y modular
- DocumentaciÃ³n paso a paso (reproducible)
- Buenas prÃ¡cticas con uv (sin pip)
- Pipeline completo: scrapeo â†’ histÃ³rico â†’ reporte HTML
- Base lista para Docker + automatizaciÃ³n

Este repo estÃ¡ pensado como proyecto de portfolio, no como un script suelto.

---

## ğŸ¯ Objetivo

Monitorizar el precio de iPhone 15, 16 y 17, guardar un histÃ³rico y generar un HTML con timeline de cambios.

Fuente de datos (segura para scraping, controlada por nosotros):  
https://andres-torrez.github.io/iphone-catalog/

---

## ğŸ§­ Roadmap (lo que construiremos)

Este proyecto se desarrolla por hitos (y se controla en el Kanban):

- âœ… Repo + Kanban + Issues + README base
- âœ… Scaffold con uv + estructura de carpetas
- âœ… CLI mÃ­nimo (healthcheck)
- â³ Scraper modular por fuentes (sources)
- â³ ExportaciÃ³n CSV y JSON
- â³ Descarga de imÃ¡genes del producto
- â³ GeneraciÃ³n de HTML dashboard con timeline
- â³ Tests + lint
- â³ Docker
- â³ AutomatizaciÃ³n (cron o GitHub Actions)

---

## ğŸ§± Estructura del proyecto (actual)

```
iphone-price-monitor/
â”‚
â”œâ”€â”€ scraper/                     # Core application
â”‚   â”œâ”€â”€ cli.py                   # Entry point (commands)
â”‚   â”œâ”€â”€ config.py                # Global configuration
â”‚   â”œâ”€â”€ models.py                # Data models (Pydantic)
â”‚   â”œâ”€â”€ http_client.py           # HTTP utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ sources/                 # Website adapters (scrapers)
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â””â”€â”€ github_pages_catalog.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/                # Data processing pipeline
â”‚   â”‚   â”œâ”€â”€ run.py
â”‚   â”‚   â”œâ”€â”€ normalize.py
â”‚   â”‚   â””â”€â”€ dedupe.py
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/                 # Data persistence
â”‚   â”‚   â”œâ”€â”€ csv_store.py
â”‚   â”‚   â””â”€â”€ json_store.py
â”‚   â”‚
â”‚   â”œâ”€â”€ media/                   # Image download logic
â”‚   â”‚   â””â”€â”€ images.py
â”‚   â”‚
â”‚   â””â”€â”€ report/                  # HTML generation
â”‚       â”œâ”€â”€ render.py
â”‚       â””â”€â”€ templates/
â”‚           â””â”€â”€ index.html.j2
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Raw responses (optional)
â”‚   â””â”€â”€ processed/               # CSV / JSON history
â”‚
â”œâ”€â”€ reports/                     # Generated HTML dashboard
â”‚
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ images/                  # Downloaded product images
â”‚   â””â”€â”€ docs/                    # Screenshots and diagrams
â”‚
â”œâ”€â”€ tests/                       # Pytest tests
â”‚
â”œâ”€â”€ .github/workflows/           # CI and scheduled runs
â”‚
â”œâ”€â”€ pyproject.toml               # Project definition (uv)
â””â”€â”€ README.md
```

---

## âš™ï¸ pyproject.toml (lo que tenemos y quÃ© significa)

Actualmente tu pyproject.toml contiene:

```
[project]
name = "iphone-price-monitor"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.13"
dependencies = [
    "httpx>=0.28.1",
    "jinja2>=3.1.6",
    "pydantic>=2.12.5",
    "selectolax>=0.4.6",
]

[tool.ruff]
line-length = 100
target-version = "py312"

[tool.ruff.lint]
select = ["E", "F", "I", "B", "UP"]

[dependency-groups]
dev = [
    "pytest>=9.0.2",
    "ruff>=0.14.14",
]
```

### âœ… ExplicaciÃ³n rÃ¡pida:

- `[project]` define el paquete (nombre, versiÃ³n, python requerido)
- `dependencies` son librerÃ­as necesarias para correr el scraper
- `dependency-groups.dev` son dependencias solo para desarrollo (tests/lint)
- `ruff` es el linter/formateador para mantener cÃ³digo limpio y consistente

Nota: tu `requires-python = ">=3.13"` y `target-version = "py312"` estÃ¡n desalineados.  
MÃ¡s adelante lo vamos a dejar consistente (recomendaciÃ³n: Python 3.12 o 3.13, pero ambos alineados).

---

## ğŸš€ Paso 1 â€” InstalaciÃ³n del entorno con uv

### 1.1 Instalar uv  
GuÃ­a oficial: https://docs.astral.sh/uv/

### 1.2 Inicializar el proyecto

```
uv init
```

### 1.3 Fijar versiÃ³n de Python (recomendado)

Ejemplo (si usas 3.12):

```
uv python pin 3.12
```

### 1.4 Instalar dependencias

```
uv add httpx selectolax pydantic jinja2
uv add --dev pytest ruff
```

---

## ğŸ“ Paso 2 â€” Crear estructura de carpetas y archivos

Creamos la arquitectura del repo (modular, escalable) con:

```
mkdir -p scraper/sources scraper/storage scraper/report/templates scraper/pipeline scraper/media
mkdir -p data/raw data/processed reports assets/images assets/docs tests .github/workflows
```

Crear archivos base:

```
touch scraper/__init__.py scraper/cli.py scraper/config.py scraper/models.py scraper/http_client.py
touch scraper/sources/__init__.py scraper/sources/base.py scraper/sources/github_pages_catalog.py
touch scraper/storage/__init__.py scraper/storage/csv_store.py scraper/storage/json_store.py
touch scraper/report/__init__.py scraper/report/render.py scraper/report/templates/index.html.j2
touch scraper/pipeline/__init__.py scraper/pipeline/run.py scraper/pipeline/normalize.py scraper/pipeline/dedupe.py
touch scraper/media/__init__.py scraper/media/images.py
touch tests/test_normalize.py tests/test_dedupe.py
touch .gitignore
```

---

## ğŸ§ª Paso 3 â€” Implementar y probar el CLI (scraper/cli.py)

Este archivo es el punto de entrada: recibe comandos desde terminal.

### âœ… Contenido actual de scraper/cli.py (tal cual lo tienes):

```
from __future__ import annotations

import argparse
from datetime import UTC, datetime


def cmd_healthcheck() -> None:
    now = datetime.now(UTC).isoformat()
    print(f"[ok] scraper CLI is working | utc={now}")


def main() -> None:
    parser = argparse.ArgumentParser(
        prog="scraper",
        description="iPhone Price Monitor CLI",
    )
    sub = parser.add_subparsers(dest="command", required=True)

    sub.add_parser("healthcheck", help="Validate the CLI runs")

    args = parser.parse_args()

    if args.command == "healthcheck":
        cmd_healthcheck()
    else:
        raise SystemExit("Unknown command")


if __name__ == "__main__":
    main()
```

### Â¿QuÃ© hace cada parte?

- `argparse` crea comandos tipo: healthcheck, run, etc.
- `cmd_healthcheck()` imprime un mensaje con la hora UTC para confirmar que todo corre
- `main()` decide quÃ© comando ejecutar
- `python -m scraper.cli ...` ejecuta este mÃ³dulo como programa

### âœ… Probar el CLI:

```
uv run python -m scraper.cli healthcheck
```

Salida esperada (ejemplo):

```
[ok] scraper CLI is working | utc=2026-02-05T...
```

---

## ğŸ§¹ Paso 4 â€” Lint con Ruff

Ruff mantiene el cÃ³digo limpio desde el primer dÃ­a.

Ejecutar:

```
uv run ruff check .
```

---

## â–¶ï¸ Â¿QuÃ© pasarÃ¡ cuando ejecutemos run?

MÃ¡s adelante aÃ±adiremos el comando:

```
uv run python -m scraper.cli run
```

Ese comando harÃ¡ este flujo:

```
cli.py
  â†“
pipeline/run.py           (orquesta el proceso)
  â†“
sources/...               (scraping)
  â†“
pipeline/normalize.py     (limpia y normaliza precios)
  â†“
pipeline/dedupe.py        (evita duplicados)
  â†“
storage/csv_store.py      (guarda CSV histÃ³rico)
storage/json_store.py     (guarda JSON histÃ³rico)
  â†“
media/images.py           (descarga imÃ¡genes del producto)
  â†“
report/render.py          (genera HTML final)
  â†“
reports/index.html
```

---

## ğŸ“‚ Â¿DÃ³nde se guardarÃ¡n los resultados?

| Resultado            | Carpeta                      |
|---------------------|------------------------------|
| CSV histÃ³rico       | data/processed/prices.csv    |
| JSON histÃ³rico      | data/processed/prices.json   |
| ImÃ¡genes descargadas| assets/images/               |
| HTML final          | reports/index.html           |

---

## âœ… Commits (lo que ya hicimos)

- Scaffold del proyecto con uv
- Estructura modular
- CLI healthcheck funcionando
- ConfiguraciÃ³n de Ruff en pyproject.toml
- README documentando todo paso a paso

---

## ğŸ§© PrÃ³ximo paso (Issue: feat(scraper))

Ahora que la base estÃ¡ lista, el siguiente hito serÃ¡:

### âœ… Implementar el scraper real para:

- iPhone 15  
- iPhone 16  
- iPhone 17  

Desde:  
https://andres-torrez.github.io/iphone-catalog/

Y empezar a generar histÃ³rico.
```

---

Si quieres, puedo convertirlo tambiÃ©n en una **versiÃ³n con Ã­ndice automÃ¡tico**, o aÃ±adir **badges**, o incluso un **diagrama visual del pipeline**.

