# ğŸ“± iPhone Price Monitor

> A productionâ€‘style scraping system that tracks price evolution, stores historical data, caches media locally, and generates an interactive dashboard.

This project demonstrates how realâ€‘world data pipelines are designed, structured, and evolved.

---

## âœ¨ Why this project matters

Most scraping examples online are just single scripts.

This repository shows how to build something closer to what companies expect:

- modular architecture  
- source adapter pattern  
- reproducible environments  
- historical storage  
- media caching  
- reporting layer  
- automated validation  
- extensibility for future sources  

---

## ğŸ¯ Objective

Monitor price changes for:

- iPhone 15  
- iPhone 16  
- iPhone 17  

Store snapshots over time and visualize trends in an HTML dashboard.

Scrapingâ€‘safe catalog (controlled environment):  
https://andres-torrez.github.io/iphone-catalog/

---

## ğŸ–¼ Example Output

After running the pipeline, an HTML report is generated with:

- current price per model  
- variation vs previous snapshot  
- timeline chart  
- local product images  
- link to the source page  

*(Add screenshots in `assets/docs/` and reference them here.)*

---

## ğŸ§± System Architecture

```
CLI
â†“
Source Adapter
â†“
Normalization
â†“
Deduplication
â†“
Storage (CSV / JSON)
â†“
Media Cache
â†“
HTML Report
```

Each component is isolated and replaceable.

---

## ğŸ§© Tech Stack

- Python  
- uv (dependency & environment management)  
- httpx  
- selectolax  
- pydantic  
- jinja2  
- pytest  
- ruff  
- Chart.js  

---

## ğŸ“‚ Repository layout

```text
scraper/
  sources/        # website adapters
  pipeline/       # transformations
  storage/        # persistence
  media/          # image downloads
  report/         # dashboard generation

data/             # historical outputs
assets/           # images & docs
reports/          # generated site
tests/            # validations
```

---

## ğŸš€ Quick Start

```bash
uv sync
uv pip install -e .
uv run python -m scraper.cli run
```

Open:

```
reports/index.html
```

---

## ğŸ“š Step-by-step build

The project is intentionally constructed in milestones.

You can reproduce the entire system from scratch.

```
docs/
â”œâ”€â”€ 01_setup.md
â”œâ”€â”€ 02_source_adapter.md
â”œâ”€â”€ 03_pipeline.md
â”œâ”€â”€ 04_media.md
â”œâ”€â”€ 05_report.md
```

---

## ğŸ§ª Quality checks

```bash
uv run pytest
uv run ruff check .
```

---

## ğŸ“ˆ What recruiters usually like in this repo

- separation of concerns  
- evolution through commits  
- honest troubleshooting documentation  
- deterministic outputs  
- CLI interface  
- test coverage  
- clean dependency management  
- clear path to Docker & CI  

---

## ğŸ”® Future ideas

- additional data stores  
- notifications / alerts  
- public API  
- cloud execution  
- more visual analytics  

---

## ğŸ‘¨â€ğŸ’» Author

Built as a professional portfolio project to demonstrate practical software engineering in scraping and data pipelines.
