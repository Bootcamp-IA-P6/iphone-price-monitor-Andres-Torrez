<<<<<<< HEAD
# ðŸ“± iPhone Price Monitor

A modular, documented and reproducible web scraping project that monitors iPhone prices over time and generates a visual HTML dashboard.

This project is designed as a **portfolio-quality example** of:
- Clean project architecture
- Modular scraping design
- Data persistence
- Automated reporting
- Dockerization and scheduling
- Professional documentation

---

## ðŸŽ¯ Goal

Monitor price changes for iPhone models (15, 16, 17) from a controlled source website and build a historical dataset with visual reporting.

Source website (scraping-safe):
https://andres-torrez.github.io/iphone-catalog/

---

## ðŸ—‚ï¸ Project Structure

```
iphone-price-monitor/
â”‚
â”œâ”€â”€ scraper/                     # Core application
â”‚   â”œâ”€â”€ cli.py                   # Entry point (commands)
â”‚   â”œâ”€â”€ config.py                # Global configuration
â”‚   â”œâ”€â”€ models.py                # Data models (Pydantic)
â”‚   â”œâ”€â”€ http_client.py          # HTTP utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ sources/                # Website adapters (scrapers)
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â””â”€â”€ github_pages_catalog.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/               # Data processing pipeline
â”‚   â”‚   â”œâ”€â”€ run.py
â”‚   â”‚   â”œâ”€â”€ normalize.py
â”‚   â”‚   â””â”€â”€ dedupe.py
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/                # Data persistence
â”‚   â”‚   â”œâ”€â”€ csv_store.py
â”‚   â”‚   â””â”€â”€ json_store.py
â”‚   â”‚
â”‚   â”œâ”€â”€ media/                  # Image download logic
â”‚   â”‚   â””â”€â”€ images.py
â”‚   â”‚
â”‚   â””â”€â”€ report/                 # HTML generation
â”‚       â”œâ”€â”€ render.py
â”‚       â””â”€â”€ templates/
â”‚           â””â”€â”€ index.html.j2
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Raw responses (optional)
â”‚   â””â”€â”€ processed/              # CSV / JSON history
â”‚
â”œâ”€â”€ reports/                    # Generated HTML dashboard
â”‚
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ images/                 # Downloaded product images
â”‚   â””â”€â”€ docs/                   # Screenshots and diagrams
â”‚
â”œâ”€â”€ tests/                      # Pytest tests
â”‚
â”œâ”€â”€ .github/workflows/          # CI and scheduled runs
â”‚
â”œâ”€â”€ pyproject.toml              # Project definition (uv)
â””â”€â”€ README.md
```


---

## âš™ï¸ Requirements

- Python 3.12+
- uv (package and environment manager)

Install uv:
https://docs.astral.sh/uv/

---

## ðŸ Virtual Environment with uv (no manual activation)

This project uses **uv** instead of pip and venv.

You do **not** activate a virtual environment manually.

uv automatically creates and manages an isolated environment for the project.

### First time setup

```bash
uv init
uv python pin 3.12
uv add httpx selectolax pydantic jinja2
uv add --dev pytest ruff
```

### Running commands

Always use:

```bash
uv run <command>
```

Examples:

```bash
uv run python -m scraper.cli healthcheck
uv run ruff check .
uv run pytest
```

uv ensures all commands run inside the project environment automatically.


## ðŸš€ Installation

```bash
uv init
uv add httpx selectolax pydantic jinja2
uv add --dev pytest ruff
```

---

## â–¶ï¸ Run the pipeline

```bash
uv run python -m scraper.cli run
```

This will:

1. Scrape product data
2. Store historical data in CSV and JSON
3. Download product images
4. Generate an HTML dashboard

---

## ðŸ“Š Outputs

After running, you will find:

- `data/processed/prices.csv`
- `data/processed/prices.json`
- `reports/index.html`
- `assets/images/*.png`

---

## ðŸ§  Architecture

The scraper is built using a **source adapter pattern**:

```
sources â†’ normalize â†’ store â†’ report
```

This allows adding new websites without modifying the pipeline.

---

## ðŸ—ºï¸ Roadmap

See the GitHub Project board for step-by-step development progress.

---

## ðŸ³ Docker & Automation (later steps)

The project will be dockerized and scheduled via cron or GitHub Actions.
=======
>>>>>>> 0af7798 (chore: scaffold project structure with uv)
